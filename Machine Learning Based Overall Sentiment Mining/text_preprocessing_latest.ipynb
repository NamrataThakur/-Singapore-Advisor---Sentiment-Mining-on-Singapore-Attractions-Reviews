{"cells":[{"cell_type":"code","execution_count":null,"id":"c0d3e0c4","metadata":{"id":"c0d3e0c4","outputId":"f4ee23c7-53dc-45a7-a2ac-5790e32d66f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langdetect"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","     -------------------------------------- 981.5/981.5 kB 1.1 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: six in c:\\users\\public\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py): started\n","  Building wheel for langdetect (setup.py): finished with status 'done'\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=960ababbc79211dd53b4b20dcf06d2e80aa0a110037bfb8a3b2357462b44a683\n","  Stored in directory: c:\\users\\namrata thakur\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n"]}],"source":["!pip install langdetect\n","!pip install contractions\n"]},{"cell_type":"code","execution_count":null,"id":"bbfa0f1b","metadata":{"id":"bbfa0f1b"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from langdetect import detect\n","import string\n","import matplotlib.pyplot as plt\n","from glob import glob\n","#text preprocess file\n","import unicodedata\n","import contractions         \n","import re\n","import nltk\n","from nltk import sent_tokenize\n","from nltk.stem import LancasterStemmer\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","execution_count":null,"id":"a69e92b2","metadata":{"id":"a69e92b2"},"outputs":[],"source":["# get list of file names\n","#csv_files = glob('../data/ReviewData/*.csv')#\n","csv_files = glob('review_consolidated.csv')\n","# Get the default list of stopwords\n","stopwords_list = stopwords.words('english')\n","# Create a new list without negation words\n","new_stopwords_list = [word for word in stopwords_list if word not in ['not', 'never', 'no', 'none']]\n"]},{"cell_type":"code","execution_count":null,"id":"d795d4a4","metadata":{"id":"d795d4a4","outputId":"a3f10b87-315a-46d0-bf05-50b81b0b3426"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Namrata Thakur\\AppData\\Local\\Temp\\ipykernel_19672\\2829852895.py:7: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n","  d = pd.read_csv(f)\n"]}],"source":["# validating count of columns for all files and fixing the troublesome files\n","\n","df = []\n","\n","for f in csv_files:\n","    try:\n","        d = pd.read_csv(f)\n","        if d.shape[1]!=9:\n","            print(f)\n","    except:\n","        d = pd.read_csv(f,encoding='ISO-8859-1')\n","        d = d.drop([c for c in d.columns if 'Unnamed' in c], axis=1)\n","        d = d.rename(columns={'Merlion_Park':'place'})\n","    \n","    df.append(d)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"257991d2","metadata":{"id":"257991d2"},"outputs":[],"source":["# concatenating all dataframes \n","data = pd.concat(df, ignore_index=True)\n","\n","# save data in to dataframe\n","# data.to_csv('../data/review_consolidated.csv', index=False)"]},{"cell_type":"markdown","id":"b18be5c3","metadata":{"id":"b18be5c3"},"source":["# Load the data"]},{"cell_type":"code","execution_count":null,"id":"49d6c328","metadata":{"id":"49d6c328","outputId":"ab192157-9e8c-4509-c5f4-4ab165b8e802"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/wd/s9qh73dx1hbc5dsw2drwrtph0000gn/T/ipykernel_13530/2468390757.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv('../data/review_consolidated_drive.csv')\n"]}],"source":["data = pd.read_csv('../data/review_consolidated_drive.csv')"]},{"cell_type":"code","execution_count":null,"id":"07b7a29e","metadata":{"id":"07b7a29e","outputId":"80cf7c76-72e2-4a65-9f52-219053f1cf74"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>place</th>\n","      <th>reviewer</th>\n","      <th>reviewer_location</th>\n","      <th>reviewer_contributions</th>\n","      <th>review_rating</th>\n","      <th>review_type</th>\n","      <th>review_date</th>\n","      <th>review_title</th>\n","      <th>review_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>River Wonders</td>\n","      <td>jaytara</td>\n","      <td>Singapore, Singapore</td>\n","      <td>648.0</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>June 1, 2022</td>\n","      <td>Poorly signposted</td>\n","      <td>It's a long walk from the carpark to the River...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>River Wonders</td>\n","      <td>OceanMasterII</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>Family</td>\n","      <td>May 2, 2022</td>\n","      <td>May 2022 Visit</td>\n","      <td>Having visited Singapore Zoo and Night Safari ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>River Wonders</td>\n","      <td>Oscardog16</td>\n","      <td>Adelaide, Australia</td>\n","      <td>1014.0</td>\n","      <td>4.0</td>\n","      <td>NaN</td>\n","      <td>December 27, 2022</td>\n","      <td>Nice size park to spend 3 hours</td>\n","      <td>Many walkways are covered so you are not in th...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>River Wonders</td>\n","      <td>CSK</td>\n","      <td>Singapore, Singapore</td>\n","      <td>114.0</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>May 4, 2022</td>\n","      <td>Nothing much. Tix only worth for the pandas.</td>\n","      <td>The entrance fee for adults varies from $38-$4...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>River Wonders</td>\n","      <td>SmithySy57</td>\n","      <td>Woking, UK</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>Family</td>\n","      <td>January 3, 2020</td>\n","      <td>Waste of a lot of time</td>\n","      <td>Disappointing visit with very long queues mult...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           place       reviewer     reviewer_location  reviewer_contributions  \\\n","0  River Wonders        jaytara  Singapore, Singapore                   648.0   \n","1  River Wonders  OceanMasterII                   NaN                     NaN   \n","2  River Wonders     Oscardog16   Adelaide, Australia                  1014.0   \n","3  River Wonders            CSK  Singapore, Singapore                   114.0   \n","4  River Wonders     SmithySy57            Woking, UK                     8.0   \n","\n","  review_rating review_type        review_date  \\\n","0           3.0         NaN       June 1, 2022   \n","1           3.0      Family        May 2, 2022   \n","2           4.0         NaN  December 27, 2022   \n","3           2.0         NaN        May 4, 2022   \n","4           1.0      Family    January 3, 2020   \n","\n","                                   review_title  \\\n","0                             Poorly signposted   \n","1                                May 2022 Visit   \n","2               Nice size park to spend 3 hours   \n","3  Nothing much. Tix only worth for the pandas.   \n","4                        Waste of a lot of time   \n","\n","                                         review_text  \n","0  It's a long walk from the carpark to the River...  \n","1  Having visited Singapore Zoo and Night Safari ...  \n","2  Many walkways are covered so you are not in th...  \n","3  The entrance fee for adults varies from $38-$4...  \n","4  Disappointing visit with very long queues mult...  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","id":"14e93961","metadata":{"id":"14e93961"},"source":["# Preprocess Text"]},{"cell_type":"code","execution_count":null,"id":"a48ea7c9","metadata":{"id":"a48ea7c9"},"outputs":[],"source":["def replace_contractions(text):\n","    \"\"\"Replace contractions in string of text\"\"\"\n","    return contractions.fix(text)\n","\n","\n","def remove_non_ascii(text):\n","    # Define a list of ASCII characters\n","    ascii_letters = string.ascii_letters + string.digits + string.punctuation + ' '\n","    \n","    # Filter out non-ASCII characters\n","    ascii_text = ''.join(filter(lambda x: x in ascii_letters, text))\n","    \n","    return ascii_text\n","\n","def remove_special_characters(text):\n","    # Define the pattern to match special characters\n","    pattern = r'[^a-zA-Z\\s]'\n","    # Remove the special characters\n","    filtered_text = re.sub(pattern, '', text)\n","    return filtered_text\n","\n","def replace_numbers(words):\n","    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n","    p = inflect.engine()\n","    new_words = []\n","    for word in words:\n","        if word.isdigit():\n","            new_word = p.number_to_words(word)\n","            new_words.append(new_word)\n","        else:\n","            new_words.append(word)\n","    return new_words\n","\n","def remove_stopwords(text):\n","    # Define a list of stopwords for the English language\n","    stop_words = set(stopwords.words('english'))\n","    # Split the text into words\n","    words = text.split()\n","    # Remove the stopwords\n","    filtered_words = [word for word in words if word.lower() not in stop_words]\n","    # Join the filtered words back into a text string\n","    filtered_text = ' '.join(filtered_words)\n","    return filtered_text\n","\n"]},{"cell_type":"code","execution_count":null,"id":"87e8e1ba","metadata":{"id":"87e8e1ba","outputId":"e89cd95c-b6f1-446a-f31c-ed6a59fc62e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 9min 25s, sys: 4.04 s, total: 9min 29s\n","Wall time: 9min 31s\n"]}],"source":["%%time\n","def detect_lang(reviews):\n","    cn = [] \n","    for x in reviews:\n","        try:\n","            lang = detect(x)\n","        except:\n","            lang = 'others'\n","        cn.append(lang)\n","    return cn\n","\n","data['language'] = detect_lang(data['review_text'].values)"]},{"cell_type":"code","execution_count":null,"id":"1f92aec9","metadata":{"id":"1f92aec9"},"outputs":[],"source":["# remove non english text\n","data1 = data[data['language']=='en']\n","data1.to_csv('review_consolidated_lang.csv')"]},{"cell_type":"code","execution_count":null,"id":"6a37a9c3","metadata":{"id":"6a37a9c3"},"outputs":[],"source":["wnl = nltk.WordNetLemmatizer()\n","def pos_tagger(review):\n","    #print(review)\n","    lemma_text = []\n","    text = nltk.word_tokenize(review)\n","    pos_text = nltk.pos_tag(text)\n","    for word, tag in pos_text:\n","        if tag[0] in ['N', 'V', 'J', 'R']:\n","            if tag in ('NN','NNPS','NNP','NNS','RB', 'RBR', 'RBS','VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ','ADV'):\n","                lemma_text.append(wnl.lemmatize(word,pos= tag[0].lower()))\n","            elif tag in ('JJR', 'JJS','JJ'):\n","                lemma_text.append(wnl.lemmatize(word, pos = 'a'))\n","            else:\n","                lemma_text.append(word)\n","    return lemma_text\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"681d2e12","metadata":{"id":"681d2e12","outputId":"bb7d3ae9-4037-4366-99d4-9be6fa2d9d26"},"outputs":[{"data":{"text/plain":["[('bundling', 'VBG'), ('interesting', 'VBG')]"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["nltk.pos_tag(['bundling','interesting'])\n","\n"]},{"cell_type":"code","execution_count":null,"id":"35b8340a","metadata":{"id":"35b8340a"},"outputs":[],"source":["def lemmatization_tagger(text):\n","    lemma_text = []\n","    #print(text)\n","    for review in tqdm(text):\n","#         print(review)\n","        clean_text = pos_tagger(review)\n","        lemma_text.append((' '.join(clean_text)))\n","    return lemma_text"]},{"cell_type":"code","execution_count":null,"id":"78445f2a","metadata":{"id":"78445f2a","outputId":"a40e2399-833a-4fb3-8fd9-b4650cab050e"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 24.5 s, sys: 1.94 s, total: 26.5 s\n","Wall time: 26.5 s\n"]},{"name":"stderr","output_type":"stream","text":["<timed exec>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}],"source":["%%time\n","def preprocess(text):\n","    text = replace_contractions(text)\n","    text = remove_non_ascii(text)\n","    text = text.lower()\n","    text = remove_stopwords(text)\n","    text = remove_special_characters(text)\n","    return text\n","\n","\n","data1['preprocessed_text'] = data1['review_text'].apply(preprocess)"]},{"cell_type":"code","execution_count":null,"id":"48ce9fac","metadata":{"id":"48ce9fac","scrolled":true,"outputId":"f31bad08-08c0-475e-f1bd-7870d94fb667"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████| 195706/195706 [04:49<00:00, 676.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 4min 45s, sys: 4.14 s, total: 4min 49s\n","Wall time: 4min 49s\n"]},{"name":"stderr","output_type":"stream","text":["<timed exec>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>place</th>\n","      <th>reviewer</th>\n","      <th>reviewer_location</th>\n","      <th>reviewer_contributions</th>\n","      <th>review_rating</th>\n","      <th>review_type</th>\n","      <th>review_date</th>\n","      <th>review_title</th>\n","      <th>review_text</th>\n","      <th>language</th>\n","      <th>preprocessed_text</th>\n","      <th>lemmatized_clean_review_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>River Wonders</td>\n","      <td>jaytara</td>\n","      <td>Singapore, Singapore</td>\n","      <td>648.0</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>June 1, 2022</td>\n","      <td>Poorly signposted</td>\n","      <td>It's a long walk from the carpark to the River...</td>\n","      <td>en</td>\n","      <td>long walk carpark river wonders entrance insid...</td>\n","      <td>long walk carpark river wonder entrance signpo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>River Wonders</td>\n","      <td>OceanMasterII</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>Family</td>\n","      <td>May 2, 2022</td>\n","      <td>May 2022 Visit</td>\n","      <td>Having visited Singapore Zoo and Night Safari ...</td>\n","      <td>en</td>\n","      <td>visited singapore zoo night safari numerous ti...</td>\n","      <td>visit singapore zoo night safari numerous time...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>River Wonders</td>\n","      <td>Oscardog16</td>\n","      <td>Adelaide, Australia</td>\n","      <td>1014.0</td>\n","      <td>4.0</td>\n","      <td>NaN</td>\n","      <td>December 27, 2022</td>\n","      <td>Nice size park to spend 3 hours</td>\n","      <td>Many walkways are covered so you are not in th...</td>\n","      <td>en</td>\n","      <td>many walkways covered baking sun  pm animal sh...</td>\n","      <td>many walkway cover bake sun pm animal show boo...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>River Wonders</td>\n","      <td>CSK</td>\n","      <td>Singapore, Singapore</td>\n","      <td>114.0</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>May 4, 2022</td>\n","      <td>Nothing much. Tix only worth for the pandas.</td>\n","      <td>The entrance fee for adults varies from $38-$4...</td>\n","      <td>en</td>\n","      <td>entrance fee adults varies  depending citizen ...</td>\n","      <td>entrance fee adult varies depend citizen forei...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>River Wonders</td>\n","      <td>SmithySy57</td>\n","      <td>Woking, UK</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>Family</td>\n","      <td>January 3, 2020</td>\n","      <td>Waste of a lot of time</td>\n","      <td>Disappointing visit with very long queues mult...</td>\n","      <td>en</td>\n","      <td>disappointing visit long queues multiple times...</td>\n","      <td>disappointing visit long queues multiple time ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           place       reviewer     reviewer_location  reviewer_contributions  \\\n","0  River Wonders        jaytara  Singapore, Singapore                   648.0   \n","1  River Wonders  OceanMasterII                   NaN                     NaN   \n","2  River Wonders     Oscardog16   Adelaide, Australia                  1014.0   \n","3  River Wonders            CSK  Singapore, Singapore                   114.0   \n","4  River Wonders     SmithySy57            Woking, UK                     8.0   \n","\n","  review_rating review_type        review_date  \\\n","0           3.0         NaN       June 1, 2022   \n","1           3.0      Family        May 2, 2022   \n","2           4.0         NaN  December 27, 2022   \n","3           2.0         NaN        May 4, 2022   \n","4           1.0      Family    January 3, 2020   \n","\n","                                   review_title  \\\n","0                             Poorly signposted   \n","1                                May 2022 Visit   \n","2               Nice size park to spend 3 hours   \n","3  Nothing much. Tix only worth for the pandas.   \n","4                        Waste of a lot of time   \n","\n","                                         review_text language  \\\n","0  It's a long walk from the carpark to the River...       en   \n","1  Having visited Singapore Zoo and Night Safari ...       en   \n","2  Many walkways are covered so you are not in th...       en   \n","3  The entrance fee for adults varies from $38-$4...       en   \n","4  Disappointing visit with very long queues mult...       en   \n","\n","                                   preprocessed_text  \\\n","0  long walk carpark river wonders entrance insid...   \n","1  visited singapore zoo night safari numerous ti...   \n","2  many walkways covered baking sun  pm animal sh...   \n","3  entrance fee adults varies  depending citizen ...   \n","4  disappointing visit long queues multiple times...   \n","\n","                        lemmatized_clean_review_text  \n","0  long walk carpark river wonder entrance signpo...  \n","1  visit singapore zoo night safari numerous time...  \n","2  many walkway cover bake sun pm animal show boo...  \n","3  entrance fee adult varies depend citizen forei...  \n","4  disappointing visit long queues multiple time ...  "]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","data1['lemmatized_clean_review_text'] = lemmatization_tagger(data1['preprocessed_text'])\n","data1.head()\n"]},{"cell_type":"code","execution_count":null,"id":"d781b935","metadata":{"id":"d781b935"},"outputs":[],"source":["# save data in to dataframe\n","data1.to_csv('../data/preprocessed_reviews_lemmatised.csv', index=False)\n"]},{"cell_type":"markdown","id":"768205f3","metadata":{"id":"768205f3"},"source":["# Split the data in to train and test"]},{"cell_type":"code","execution_count":null,"id":"82e491c8","metadata":{"id":"82e491c8"},"outputs":[],"source":["sampled, unseen = train_test_split(data1, random_state=0, test_size=0.5)\n","train, test = train_test_split(sampled, random_state=0, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"id":"8b494f2b","metadata":{"id":"8b494f2b","outputId":"e0c7cc1a-9e1b-43d0-84e9-c7a49b69ef54"},"outputs":[{"data":{"text/plain":["((78282, 12), (19571, 12), (97853, 12))"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["train.shape, test.shape, unseen.shape"]},{"cell_type":"markdown","id":"68f163dc","metadata":{"id":"68f163dc"},"source":["Transforming the data using Tfidf Vectoriser and word2vec"]},{"cell_type":"code","execution_count":null,"id":"fa1bb807","metadata":{"id":"fa1bb807"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from gensim.models import Word2Vec\n","from sklearn.pipeline import Pipeline\n","import pickle\n","\n","sentences = [sentence.split() for sentence in train['lemmatized_clean_review_text']]\n","w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n","w2v_words = w2v_model.wv.index_to_key\n","\n","# Define the TF-IDF vectorizer\n","vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=10000)\n"]},{"cell_type":"code","execution_count":null,"id":"5658c067","metadata":{"id":"5658c067","outputId":"3c4f0318-d22e-4ec5-8564-2dde1854a178"},"outputs":[{"name":"stdout","output_type":"stream","text":["number of words that occured minimum 5 times  10712\n","sample words  ['singapore', 'visit', 'place', 'see', 'go', 'garden', 'get', 'time', 'great', 'take', 'walk', 'well', 'view', 'good', 'day', 'zoo', 'also', 'night', 'show', 'food', 'many', 'beautiful', 'shop', 'enjoy', 'lot', 'animal', 'experience', 'really', 'area', 'bay', 'nice', 'worth', 'make', 'even', 'city', 'way', 'park', 'best', 'look', 'flower', 'light', 'hour', 'much', 'love', 'find', 'orchid', 'people', 'recommend', 'tour', 'different']\n"]}],"source":["\n","print(\"number of words that occured minimum 5 times \",len(w2v_words))\n","print(\"sample words \", w2v_words[0:50])"]},{"cell_type":"code","execution_count":null,"id":"85229a9b","metadata":{"id":"85229a9b","outputId":"5331ab94-e2d3-4b5e-d6fe-d22b40b43f7d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/yashnagogineni/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["x_train_tfidf = vectorizer.fit_transform(train['lemmatized_clean_review_text'])\n","# we are converting a dictionary with word as a key, and the idf as a value\n","dictionary = dict(zip(vectorizer.get_feature_names(), list(vectorizer.idf_)))\n","     "]},{"cell_type":"code","execution_count":null,"id":"db41d9c4","metadata":{"id":"db41d9c4"},"outputs":[],"source":["def get_weighted_w2v_tfidf(vectorizer, sentences):\n","    # TF-IDF weighted Word2Vec\n","\n","    tfidf_feat = vectorizer.get_feature_names() # tfidf words/col-names\n","\n","\n","    tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n","    row=0\n","    for sent in tqdm(sentences): # for each review/sentence \n","        sent_vec = np.zeros(100) # as word vectors are of zero length\n","        weight_sum =0; # num of words with a valid vector in the sentence/review\n","        for word in sent: # for each word in a review/sentence\n","            if word in w2v_words and word in tfidf_feat:\n","                vec = w2v_model.wv[word]\n","    #             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n","                # to reduce the computation we are \n","                # dictionary[word] = idf value of word in whole courpus\n","                # sent.count(word) = tf valeus of word in this review\n","                tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n","                sent_vec += (vec * tf_idf)\n","                weight_sum += tf_idf\n","        if weight_sum != 0:\n","            sent_vec /= weight_sum\n","        tfidf_sent_vectors.append(sent_vec)\n","        row += 1\n","        \n","    print(len(tfidf_sent_vectors))\n","    return tfidf_sent_vectors"]},{"cell_type":"code","execution_count":null,"id":"a1bf787f","metadata":{"id":"a1bf787f","outputId":"d5068b39-c7ef-4dc9-cc42-a62888c9b85d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████| 78282/78282 [02:49<00:00, 462.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["78282\n"]}],"source":["train['vector'] = get_weighted_w2v_tfidf(vectorizer, sentences)"]},{"cell_type":"code","execution_count":null,"id":"e6a89ef2","metadata":{"id":"e6a89ef2","outputId":"dbed4f99-4a0d-4f1c-8167-15af424ddc98"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████| 19571/19571 [00:42<00:00, 464.61it/s]\n","/Users/yashnagogineni/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["19571\n"]},{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████| 97853/97853 [03:32<00:00, 459.66it/s]"]},{"name":"stdout","output_type":"stream","text":["97853\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["test_sentences = [sentence.split() for sentence in test['lemmatized_clean_review_text']]\n","unseen_sentences = [sentence.split() for sentence in unseen['lemmatized_clean_review_text']]\n","\n","test['vector'] = get_weighted_w2v_tfidf(vectorizer, test_sentences)\n","unseen['vector'] = get_weighted_w2v_tfidf(vectorizer, unseen_sentences)"]},{"cell_type":"code","execution_count":null,"id":"ade9991f","metadata":{"id":"ade9991f"},"outputs":[],"source":["train['is_train']='train'\n","test['is_train']='test'\n","unseen['is_train']='unseen'\n","\n","to_sav = pd.concat([train, test, unseen], axis=0)\n","to_sav.to_csv('vector.csv',index=False)"]},{"cell_type":"code","execution_count":null,"id":"0f083c6d","metadata":{"id":"0f083c6d"},"outputs":[],"source":["# def vectorize(sentence):\n","#     words = sentence.split()\n","#     words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n","#     if len(words_vecs) == 0:\n","#         return np.zeros(100)\n","#     words_vecs = np.array(words_vecs)\n","#     return words_vecs\n","\n","# x_train_tfidf = vectorizer.fit_transform(train['lemmatized_clean_review_text'])\n","# x_test_tfidf = vectorizer.transform(test['preprocessed_text'])\n","# x_unseen_tfidf = vectorizer.transform(unseen['preprocessed_text'])\n","\n","\n","# x_train_w2v = np.array([vectorize(sentence) for sentence in train['preprocessed_text']])\n","# x_test_w2v = np.array([vectorize(sentence) for sentence in test['preprocessed_text']])\n","# x_unseen_w2v = np.array([vectorize(sentence) for sentence in unseen['preprocessed_text']])\n"]},{"cell_type":"markdown","id":"93fbefe6","metadata":{"id":"93fbefe6"},"source":["reference - https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}